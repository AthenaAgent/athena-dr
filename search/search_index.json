{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Athena Deep Research","text":"<p>Our homegrown deep research model.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>git clone https://github.com/AthenaAgent/athena-dr.git\ncd athena-dr\nuv sync --all-extras --all-groups\n</code></pre> <p>Run MCP server using the following command</p> <pre><code>MCP_CACHE_DIR=\".cache-$(hostname)\" athena-dr-mcp\n</code></pre>"},{"location":"#docs","title":"Docs","text":"<ol> <li>Install the dependencies using <code>uv sync --group docs</code></li> <li>Serve the docs using <code>mkdocs serve</code></li> </ol> <p>The documentation is available at http://127.0.0.1:8000</p>"},{"location":"benchmarks/","title":"Target Benchmarks","text":""},{"location":"benchmarks/#frames-factuality-retrieval-and-reasoning-measurement-set","title":"FRAMES: Factuality, Retrieval, And reasoning MEasurement Set","text":"<p>A comprehensive evaluation dataset designed to test the capabilities of Retrieval-Augmented Generation (RAG) systems across factuality, retrieval accuracy, and reasoning.</p> Agent Base models FRAMES Proprietary Agents Deep Research o3 - GPT-5 GPT-5 - GPT-5-Pro GPT-5-Pro - o4-mini o4-mini - Kimi-researcher Kimi-k1.5/k2 78.8\u2020 gpt-oss-20b gpt-oss-20b - gpt-oss-120b gpt-oss-120b - Multi Agents OpenDeepSearch-R1 Deepseek-R1-671B 72.4* OpenDeepSearch-QwQ QwQ-32B 54.1* MiroThinker-8B Qwen3-8B&amp;235B 64.4\u2020 MiroThinker-32B Qwen3-32B&amp;235B 71.7\u2020 WebThinker-32B QwQ-32B 35.5* Single Agents WebSailor-32B Qwen2.5-32B 69.78* WebShaper-32B QwQ-32B 69.42* AFM-32B Qwen2.5-32B 55.3\u2020 SFR-DR-8B Qwen3-8B 63.3 SFR-DR-32B QwQ-32B 72.0 SFR-DR-20B gpt-oss-20b 82.8 Tongyi-DR-30B Qwen3-32B 90.6"},{"location":"benchmarks/#browsecomp-a-benchmark-for-browsing-agents","title":"BrowseComp: a benchmark for browsing agents","text":"<p>A simple and challenging benchmark that measures the ability of AI agents to locate hard-to-find information.</p> MODEL SCORE Kimi K2-Thinking-0905Moonshot AI 0.602 DeepSeek-V3.2 (Thinking)DeepSeek 0.514 GLM-4.6Zhipu AI 0.451 MiniMax M2MiniMax 0.440 Tongyi-DR-30BAlibaba 0.434 DeepSeek-V3.2-ExpDeepSeek 0.401 DeepSeek-V3.1DeepSeek 0.300 GLM-4.5Zhipu AI 0.264 GLM-4.5-AirZhipu AI 0.213 DeepSeek-R1-0528DeepSeek 0.089"},{"location":"benchmarks/#xbench-deepsearch","title":"Xbench DeepSearch","text":"<p>DeepSearch is part of xbench's AGI-Aligned series, focused on evaluating tool usage capabilities in search and information retrieval scenarios.</p> Product Accuracy Cost/Task Time Cost/Task ChatGPT-5-Pro 75+ ~$0.085 5-8min Tongyi-DR-30B 75.0 Free - SuperGrok Expert 40+ ~$0.08 3-5min Minimax Agent 35+ $69 2-3min StepFun Research 35+ Free 8-15min Flowith 35+ ~$0.1 8-15min Skywork 35+ ~$0.55 3-5min Manus Agent (Quality Mode) 35+ ~$0.63 3-5min Doubao (Deep Research) 35+ Free 5-8min Fellou 35+ ~$2 5-8min Genspark Super Agent 30+ ~$0.15 3-5min Coze Space 30+ Free 2-3min"},{"location":"cli/","title":"Command Line Interface Reference","text":"<p>Athena DR provides several command-line tools for running deep research workflows, managing MCP servers, and processing datasets.</p>"},{"location":"cli/#cli-commands-overview","title":"CLI Commands Overview","text":"Command Purpose Entry Point <code>athena-dr</code> Main workflow CLI for running auto-search workflows and dataset generation <code>athena_dr.agent.workflows.cli:launch_auto_search_workflow_cli</code> <code>athena-dr-mcp</code> Run the MCP (Model Context Protocol) server with search and browse tools <code>athena_dr.agent.mcp_backend.main:main</code> <code>athena-dr-list-tools</code> List all available tools from the MCP server in a formatted table <code>athena_dr.utils:list_tools_from_server</code> <code>athena-dr-workflows</code> Web page reader CLI to read and answer questions from web pages <code>athena_dr.agent.workflows.cli:launch_web_page_reader_cli</code>"},{"location":"cli/#athena-dr","title":"<code>athena-dr</code>","text":"<p>The main workflow CLI that provides commands for running auto-search workflows and generating dataset responses.</p>"},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#debug","title":"<code>debug</code>","text":"<p>Test the workflow setup and configuration.</p> <pre><code>athena-dr debug [--config CONFIG_FILE]\n</code></pre> Option Description <code>--config</code> Path to configuration file (uses default if not specified)"},{"location":"cli/#generate_dataset","title":"<code>generate_dataset</code>","text":"<p>Generate responses for an evaluation dataset using the auto-search workflow.</p> <pre><code>athena-dr generate-dataset DATASET_NAME [OPTIONS]\n</code></pre> Argument/Option Description <code>DATASET_NAME</code> Dataset name (e.g., <code>simpleqa</code>, <code>browsecomp</code>) <code>--num-examples</code>, <code>-n</code> Number of examples to process (or <code>ablation</code>, <code>final_run</code>) <code>--subset</code>, <code>-s</code> Dataset subset to use <code>--max-concurrent</code>, <code>-c</code> Maximum concurrent tasks (default: 5) <code>--batch-size</code>, <code>-b</code> Batch size for processing (default: 20) <code>--use-cache</code> Load from existing cache and use batch processing <code>--output</code>, <code>-o</code> Output file path <code>--config</code> Configuration file path <code>--verbose</code>, <code>-v</code> Enable verbose output <code>--config-overrides</code> Override config parameters (format: <code>param1=value1,param2=value2</code>) <code>--num_total_workers</code> Total number of workers for parallel evaluation <code>--worker_index</code> Index of current worker (0-based) <p>Example:</p> <pre><code>athena-dr generate-dataset simpleqa -n 100 -o results.jsonl --max-concurrent 10\n</code></pre>"},{"location":"cli/#rejection_sampling","title":"<code>rejection_sampling</code>","text":"<p>Run rejection sampling iterations for dataset generation.</p> <pre><code>athena-dr rejection-sampling DATASET_NAME --iteration N --output OUTPUT_FILE [OPTIONS]\n</code></pre> Option Description <code>--iteration</code> Iteration number for rejection sampling (required) <code>--output</code>, <code>-o</code> Base output file path (appended with <code>-iter-N</code>) <code>--threshold</code>, <code>-t</code> Score threshold for rejection (default: 1.0) Other options Same as <code>generate-dataset</code>"},{"location":"cli/#collect_rejection_sampling_data","title":"<code>collect_rejection_sampling_data</code>","text":"<p>Collect and merge results from multiple rejection sampling iterations.</p> <pre><code>athena-dr collect-rejection-sampling-data OUTPUT_FILE [OPTIONS]\n</code></pre> Option Description <code>OUTPUT_FILE</code> Output file path for collected results <code>--max-iterations</code> Maximum iterations to check (default: 10) <code>--verbose</code>, <code>-v</code> Enable verbose output"},{"location":"cli/#generate-sft-trace","title":"<code>generate-sft-trace</code>","text":"<p>Generate SFT (Supervised Fine-Tuning) traces from a dataset using the TraceGenerator. This command loads a dataset, generates traces using the AutoReasonSearchWorkflow, applies rejection sampling to filter out incorrect answers, and optionally exports the resulting traces to Hugging Face Hub.</p> <pre><code>athena-dr generate-sft-trace DATASET_NAME --prompt-column COLUMN --gt-answer-column COLUMN [OPTIONS]\n</code></pre> Argument/Option Description Default <code>DATASET_NAME</code> Name of the dataset to load (e.g., <code>hotpotqa/hotpot_qa</code>) (required) <code>--prompt-column</code>, <code>-p</code> Column name containing the prompts/questions (required) <code>--gt-answer-column</code>, <code>-g</code> Column name containing ground truth answers (required) <code>--auto-search-config</code>, <code>-a</code> Path to auto search configuration file <code>configs/auto_search_configs.yml</code> <code>--rejection-sampling-config</code>, <code>-r</code> Path to rejection sampling configuration file <code>configs/rejection_sampling_configs.yml</code> <code>--dataset-subset</code>, <code>-s</code> Dataset subset/configuration to load <code>None</code> <code>--dataset-split</code> Dataset split to use <code>train</code> <code>--max-examples</code>, <code>-n</code> Maximum number of examples to process <code>None</code> (all) <code>--max-attempts</code>, <code>-m</code> Maximum attempts per example for rejection sampling <code>3</code> <code>--export-dataset</code>, <code>-e</code> Hugging Face Hub dataset name to export traces to <code>None</code> <code>--project</code> Weave project name for tracing <code>athena_dr</code> <p>Example:</p> <pre><code># Generate SFT traces from HotpotQA dataset\nathena-dr generate-sft-trace hotpotqa/hotpot_qa \\\n    --prompt-column question \\\n    --gt-answer-column answer \\\n    --dataset-subset distractor \\\n    --max-examples 100 \\\n    --max-attempts 3 \\\n    --export-dataset username/hotpotqa_sft_traces\n</code></pre> <p>The command will:</p> <ol> <li>Load the specified dataset from Hugging Face Hub</li> <li>For each example, generate a trace using the AutoReasonSearchWorkflow</li> <li>Check if the generated answer is correct using rejection sampling</li> <li>Retry up to <code>--max-attempts</code> times if the answer is incorrect</li> <li>Collect successful traces and optionally export them to Hugging Face Hub</li> </ol>"},{"location":"cli/#athena-dr-mcp","title":"<code>athena-dr-mcp</code>","text":"<p>Run the MCP (Model Context Protocol) server that exposes search and web browsing tools.</p>"},{"location":"cli/#usage","title":"Usage","text":"<pre><code>athena-dr-mcp [OPTIONS]\n</code></pre>"},{"location":"cli/#options","title":"Options","text":"Option Description Default <code>--transport</code> Transport protocol (<code>stdio</code>, <code>http</code>, <code>sse</code>, <code>streamable-http</code>) <code>http</code> <code>--port</code> Port to bind to (for HTTP transports) <code>8000</code> <code>--host</code> Host address to bind to <code>127.0.0.1</code> <code>--path</code> Path for the HTTP endpoint <code>/mcp</code> <code>--log-level</code> Log level (<code>debug</code>, <code>info</code>, <code>warning</code>, <code>error</code>, <code>critical</code>) <code>info</code> <code>--no-cache</code> Disable API response caching (caching enabled)"},{"location":"cli/#available-tools","title":"Available Tools","text":"<p>The MCP server exposes the following tools:</p> Tool Tags Description <code>semantic_scholar_search</code> search, necessary Search academic papers via Semantic Scholar API <code>semantic_scholar_snippet_search</code> search Retrieve focused snippets from scientific papers <code>pubmed_search</code> search Search medical/scientific papers via PubMed API <code>massive_serve_search</code> search, necessary Dense passage retrieval via massive-serve API <code>serper_google_webpage_search</code> search, necessary General web search using Google (Serper.dev) <code>serper_google_scholar_search</code> search, necessary Academic paper search via Google Scholar <code>serper_fetch_webpage_content</code> browse, necessary Fetch webpage content via Serper.dev API <code>jina_fetch_webpage_content</code> browse Fetch webpage content via Jina Reader API <code>crawl4ai_fetch_webpage_content</code> browse, necessary Extract webpage content using Crawl4AI (local) <code>crawl4ai_docker_fetch_webpage_content</code> browse, necessary Extract webpage content using Crawl4AI (Docker) <code>webthinker_fetch_webpage_content</code> browse Extract text from URLs using advanced web parsing <code>webthinker_fetch_webpage_content_async</code> browse Async version of webthinker content extraction <code>vllm_hosted_reranker</code> rerank, necessary Rerank documents using VLLM-hosted reranker <p>Example:</p> <pre><code># Start HTTP server on port 8000\nathena-dr-mcp --transport http --port 8000\n\n# Start with stdio transport (for local MCP clients)\nathena-dr-mcp --transport stdio\n\n# Start with caching disabled\nathena-dr-mcp --no-cache\n</code></pre>"},{"location":"cli/#athena-dr-list-tools","title":"<code>athena-dr-list-tools</code>","text":"<p>List all available tools from the MCP server in a formatted, readable table.</p>"},{"location":"cli/#usage_1","title":"Usage","text":"<pre><code>athena-dr-list-tools\n</code></pre> <p>This command connects to the MCP server and displays all registered tools with their:</p> <ul> <li>Tool name</li> <li>Description</li> <li>Parameters (name, type, required status, default value)</li> </ul>"},{"location":"cli/#athena-dr-workflows","title":"<code>athena-dr-workflows</code>","text":"<p>Launch the web page reader CLI to read web pages and answer questions based on their content.</p>"},{"location":"cli/#usage_2","title":"Usage","text":"<pre><code>athena-dr-workflows URL [URL...] --question QUESTION [OPTIONS]\n</code></pre>"},{"location":"cli/#arguments-and-options","title":"Arguments and Options","text":"Argument/Option Description <code>URL</code> One or more URLs of web pages to read <code>--question</code>, <code>-q</code> The question to answer from the web pages (required) <code>--project</code>, <code>-p</code> Weave project name for tracing (default: <code>athena_dr</code>) <p>Example:</p> <pre><code>athena-dr-workflows https://example.com/article1 https://example.com/article2 \\\n    --question \"What are the main findings discussed in these articles?\"\n</code></pre>"},{"location":"cli/#environment-variables","title":"Environment Variables","text":"<p>Several environment variables can be used to configure the CLI tools:</p> Variable Description <code>MCP_INCLUDE_TAGS</code> Comma-separated list of tool tags to include (default: <code>search,browse,rerank</code>) <code>SERPER_API_KEY</code> API key for Serper.dev services <code>SEMANTIC_SCHOLAR_API_KEY</code> API key for Semantic Scholar <code>JINA_API_KEY</code> API key for Jina Reader <code>CRAWL4AI_BLOCKLIST_PATH</code> Path to blocklist file for Crawl4AI AI2 config <code>AZURE_API_KEY</code> API key for Azure services"},{"location":"plan/","title":"Plan","text":""},{"location":"plan/#objective","title":"Objective","text":"<p>What Deepresearch means to us?  -  current gpt/gemini deepresearch dumps either too much information or too high level summary over all searched information  -  we hope we can have progressive explaintions eg top level first and then more detailed explanations for each step  -  by top level explantions we can skip the part not important in deeper explanations  -  also better verifiabe citations linking what exactly its referring to no just link of referaces</p> <p>The objective is to train a comprehensive deep research agent system in the 8B parameter range (Usuing Qwen-3 8B or a similar model as the base model) that is competitive with single agent models of similar size on the following benchmarks: 1. Frames benchmark (&gt; 63.3 which is achieved by SFR-DR-8B). 2. BrowseComp benchmark (&gt; 0.434 which is achieved by Tongyi-DR-30B). 3. Xbench DeepSearch benchmark (&gt; 75.0 which is achieved by Tongyi-DR-30B). 4. WebWalkerQA benchmark (&gt; 72.2 which is achieved by Tongyi-DR-30B). 5. SimpleQA benchmark (&gt; 98.6 which is achieved by Tongyi-DR-30B).</p>"},{"location":"plan/#approach","title":"Approach","text":"<p>The approach involves 2 steps:</p> <ol> <li> <p>Identify base model:</p> <ul> <li>Qwen3 8B * &lt;-------------------------------<ul> <li>max context length is 128k with yarn</li> </ul> </li> <li>Olmo3 7b</li> <li>olmo3 8b use MHA not GQA so need more varm for inference</li> <li>rnj-1 8b<ul> <li>max context length is 32k with yarn</li> </ul> </li> <li>trinity 6b 1B MOE <ul> <li>we dont want to focus on moe, just post tranining recipe for now</li> </ul> </li> </ul> <p>if 32b: - nemotron3 32b A3b - qwen3 32b A3b - olmo3 32b - trinity 32b</p> </li> <li> <p>Deep Research Agent Scaffold: We will use a custom scaffold built on top of DR-Tulu's agentic scaffold, extending its capabilities with additional research-specific tools. The reason to build on top of DR-Tulu is because of its simple MCP-based ReACT architecture that's both easy to extend with more tools, and battle hardened through real-world use.</p> <ul> <li>Available tools:<ul> <li><code>vllm_hosted_reranker</code>: Rerank a list of documents based on their relevance to the query using VLLM hosted reranker.</li> <li><code>massive_serve_search</code>: Search for documents using massive-serve API for dense passage retrieval.</li> <li><code>serper_google_webpage_search</code>: General web search using Google Search (based on Serper.dev API). Perform general web search to find relevant webpages, articles, and online resources.</li> <li><code>serper_fetch_webpage_content</code>: Fetch the content of a webpage using Serper.dev API.</li> <li><code>jina_fetch_webpage_content</code>: Fetch the content of a webpage using Jina Reader API with timeout support.</li> <li><code>crawl4ai_fetch_webpage_content</code>: Open a specific URL and extract readable page text as snippets using Crawl4AI.</li> <li><code>webthinker_fetch_webpage_content_async</code>: Asynchronously extract text content from a single URL (webpage or PDF) using advanced web parsing.</li> </ul> </li> <li>Suggestions for more tools:<ul> <li><code>memory_read</code>: Read from a memory store for persistent context.</li> <li><code>memory_write</code>: Write to a memory store for persistent context. The memory tools would encourage the model to perform long-horizon reasoning beyond the limitations of its effective context length.</li> <li><code>code_interpreter</code>: Execute shell/python code snippets in a sandboxed environment.</li> </ul> </li> <li>Why more tools are needed?<ul> <li>Overall, this suggests that using multiple complementary search tools and allowing the model to adaptively select among them can improve both prediction quality and cost efficiency (dr tulu page 13 para 1)</li> <li>R1-32B is not able to decompose the complex query into individual components, consequently only making ambiguous queries that involve too many unknown information. The agent also has severe hallucinations, producing conclusions that are not supported by the search results. Finally, it fails to resolve all unknown information. This case study shows that existing online RL approaches only incentivize elementary search strategies. It is also worth noting that, since the turn limit is set as a small value, e.g. 4, during training, the model only exhibits a short tool-use horizon (Beyond Ten Turns: https://arxiv.org/pdf/2508.07976 | section 2)</li> <li>https://www.youtube.com/watch?v=CEvIs9y1uog&amp;t=92s</li> </ul> </li> </ul> </li> <li> <p>Supervised Fine-tuning: Model already knows to tool calls, we just need to teach them to work on long horizon tasks (so no mid training needed). The plan is to train the model on high-quality instruction-following and reasoning traces generated by putting strong frontier models in deep research agent scaffolds. If we decide to proceed with Tulu-DR scaffold, we can leverage their SFT dataset as a starting point. This dataset included rejection sampled traces from the following (but not limited to):</p> <ul> <li>OpenScholar</li> <li>Search Arena</li> <li>short-form QA datasets including WebWalker-Silver</li> <li>TaskCraft</li> <li>PopQA</li> <li>TyDiQA (English)</li> <li>MegaScience</li> <li>HotpotQA</li> <li>ScholarQA</li> </ul> </li> <li> <p>Reinforcement Learning Fine-tuning: If we have time and compute, we will do RL using the same tools as SFT. If we need to customize the model to for an enterprise customer with cutom tool calls, we can also introduce them in scaffold the RL step.</p> </li> </ol>"},{"location":"plan/#proposals","title":"Proposals","text":""},{"location":"plan/#proposed-additionaltools","title":"Proposed AdditionalTools","text":"<ol> <li>Code Interpreter: A sandboxed code interpreter that can execute shell/python code snippets in a sandboxed environment using Sandboxfusion.</li> <li>Memory Read/Write: A memory read/write tool that can read from and write to a memory store for persistent context.</li> <li>Sports DB Search: A tool that can search for very specific information about sports events, players, teams, etc. (Specifically thesportsdb)</li> </ol>"},{"location":"plan/#an-updated-version-of-evol-instruct","title":"An Updated Version of Evol Instruct","text":"<p>We can use the same approach as Evol Instruct to rewrite the prompt into a more complex version.</p> <p></p> <p>There's one more thing that we can do on top of Evol Instruct to come up with more complex queries... We can take take all the prompts from a dataset, embed them using a SoTA encoder model and then use a clustering algorithm to cluster the prompts into groups. We then sample each 2-3 prompts from each cluster and then use Evol Instruct to rewrite them into a more complex version.</p>"},{"location":"tools/","title":"MCP Server Tools","text":"<p>The RL-RAG MCP server provides a collection of tools for search, browsing, and reranking. Tools are tagged to enable selective inclusion via the <code>MCP_INCLUDE_TAGS</code> environment variable.</p>"},{"location":"tools/#tool-categories","title":"Tool Categories","text":"<ul> <li>search: Tools for searching documents and web content</li> <li>browse: Tools for fetching and parsing webpage content</li> <li>rerank: Tools for reranking search results</li> <li>necessary: Core tools marked as essential</li> </ul>"},{"location":"tools/#search-tools","title":"Search Tools","text":""},{"location":"tools/#serper_google_webpage_search","title":"<code>serper_google_webpage_search</code>","text":"<p>General web search using Google Search (based on Serper.dev API).</p> <p>Tags: <code>search</code>, <code>necessary</code></p> Parameter Type Required Default Description <code>query</code> <code>str</code> Yes - Search query string <code>num_results</code> <code>int</code> No <code>10</code> Number of results to return <code>gl</code> <code>str</code> No <code>\"us\"</code> Geolocation - country code to boost search results <code>hl</code> <code>str</code> No <code>\"en\"</code> Host language of user interface <p>Returns: Dictionary containing <code>organic</code> results, <code>knowledgeGraph</code>, <code>peopleAlsoAsk</code>, and <code>relatedSearches</code>.</p>"},{"location":"tools/#massive_serve_search","title":"<code>massive_serve_search</code>","text":"<p>Search for documents using massive-serve API for dense passage retrieval.</p> <p>Tags: <code>search</code>, <code>necessary</code></p> Parameter Type Required Default Description <code>query</code> <code>str</code> Yes - Search query string <code>n_docs</code> <code>int</code> No <code>10</code> Number of documents to return <code>domains</code> <code>str</code> No <code>\"dpr_wiki_contriever_ivfpq\"</code> Domain/index to search in <code>base_url</code> <code>str</code> No <code>None</code> Base URL for the massive-serve API <code>nprobe</code> <code>int</code> No <code>None</code> Number of probes for search <p>Returns: Dictionary containing <code>message</code>, <code>query</code>, <code>n_docs</code>, <code>results</code>, and parsed <code>data</code> list.</p>"},{"location":"tools/#browse-tools","title":"Browse Tools","text":""},{"location":"tools/#serper_fetch_webpage_content","title":"<code>serper_fetch_webpage_content</code>","text":"<p>Fetch the content of a webpage using Serper.dev API.</p> <p>Tags: <code>browse</code>, <code>necessary</code></p> Parameter Type Required Default Description <code>webpage_url</code> <code>str</code> Yes - The URL of the webpage to fetch <code>include_markdown</code> <code>bool</code> No <code>True</code> Whether to include markdown formatting in the response <p>Returns: Dictionary containing <code>text</code>, <code>markdown</code>, <code>metadata</code>, <code>url</code>, <code>success</code>, and optionally <code>error</code>.</p>"},{"location":"tools/#jina_fetch_webpage_content","title":"<code>jina_fetch_webpage_content</code>","text":"<p>Fetch the content of a webpage using Jina Reader API with timeout support.</p> <p>Tags: <code>browse</code></p> Parameter Type Required Default Description <code>webpage_url</code> <code>str</code> Yes - The URL of the webpage to fetch <code>timeout</code> <code>int</code> No <code>30</code> Request timeout in seconds <p>Returns: Dictionary containing <code>url</code>, <code>title</code>, <code>content</code>, <code>description</code>, <code>publishedTime</code>, <code>metadata</code>, <code>success</code>, and optionally <code>error</code>.</p>"},{"location":"tools/#crawl4ai_fetch_webpage_content","title":"<code>crawl4ai_fetch_webpage_content</code>","text":"<p>Open a specific URL and extract readable page text using Crawl4AI (local headless browser).</p> <p>Tags: <code>browse</code>, <code>necessary</code></p> Parameter Type Required Default Description <code>url</code> <code>str</code> Yes - URL to fetch and extract content from <code>ignore_links</code> <code>bool</code> No <code>True</code> If True, remove hyperlinks in markdown <code>use_pruning</code> <code>bool</code> No <code>False</code> Apply pruning content filter to extract main content <code>bm25_query</code> <code>str</code> No <code>None</code> Optional query to enable BM25-based content filtering <code>bypass_cache</code> <code>bool</code> No <code>True</code> If True, bypass Crawl4AI cache <code>timeout_ms</code> <code>int</code> No <code>80000</code> Per-page timeout in milliseconds <code>include_html</code> <code>bool</code> No <code>False</code> Whether to include raw HTML in the response <p>Returns: <code>Crawl4AiResult</code> with extracted webpage content including markdown-formatted text.</p>"},{"location":"tools/#webthinker_fetch_webpage_content_async","title":"<code>webthinker_fetch_webpage_content_async</code>","text":"<p>Asynchronously extract text content from a single URL (webpage or PDF) using advanced web parsing.</p> <p>Tags: <code>browse</code></p> Parameter Type Required Default Description <code>url</code> <code>str</code> Yes - URL to extract text from <code>snippet</code> <code>str</code> No <code>None</code> Optional snippet to search for and extract context around <code>keep_links</code> <code>bool</code> No <code>False</code> Whether to preserve links in the extracted text <p>Returns: Dictionary containing <code>url</code> and extracted <code>text</code> content.</p>"},{"location":"tools/#rerank-tools","title":"Rerank Tools","text":""},{"location":"tools/#vllm_hosted_reranker","title":"<code>vllm_hosted_reranker</code>","text":"<p>Rerank a list of documents based on their relevance to the query using VLLM hosted reranker.</p> <p>Tags: <code>rerank</code>, <code>necessary</code></p> Parameter Type Required Default Description <code>query</code> <code>str</code> Yes - Search query string <code>documents</code> <code>List[str]</code> Yes - List of document texts to rank <code>top_n</code> <code>int</code> Yes - Number of top documents to return <code>model_name</code> <code>str</code> Yes - Name of the reranker model (e.g., <code>\"BAAI/bge-reranker-v2-m3\"</code>) <code>api_url</code> <code>str</code> Yes - Base URL for the VLLM reranker API <p>Returns: <code>RerankerResult</code> containing reranker results with <code>method</code>, <code>model_name</code>, and ranked results.</p>"},{"location":"tools/#health-check-endpoint","title":"Health Check Endpoint","text":"<p>The server also exposes a health check endpoint:</p> <pre><code>curl http://127.0.0.1:8000/health\n</code></pre> <p>Returns <code>OK</code> if the server is running.</p>"},{"location":"tools/#redundant-tools-and-why-we-keep-them","title":"Redundant tools and why we keep them","text":"<p>There are 3 reduntant tools:</p> <ol> <li><code>jina_fetch_webpage_content</code></li> <li><code>crawl4ai_fetch_webpage_content</code></li> <li><code>webthinker_fetch_webpage_content_async</code></li> </ol>"},{"location":"tools/#comparison","title":"Comparison","text":"Aspect jina_fetch_webpage_content crawl4ai_fetch_webpage_content webthinker_fetch_webpage_content_async Backend Jina Reader API (remote) Crawl4AI (local browser) Custom aiohttp parser (local) Execution Sync Async Async Tags <code>browse</code> <code>browse</code>, <code>necessary</code> <code>browse</code> Timeout 30s 80s 240s"},{"location":"tools/#feature-differences","title":"Feature Differences","text":"Feature Jina Crawl4AI WebThinker BM25 query filtering \u274c \u2705 \u274c Content pruning \u274c \u2705 \u274c Snippet extraction \u274c \u274c \u2705 Link removal option \u274c \u2705 \u2705 (inverse: <code>keep_links</code>) Raw HTML output \u274c \u2705 \u274c PDF support \u274c \u274c \u2705 Caching control \u274c \u2705 \u274c Rich metadata \u2705 (title, description, publishedTime) \u274c \u274c"},{"location":"tools/#summary","title":"Summary","text":"<ul> <li>jina_fetch_webpage_content \u2014 Simplest option; uses external Jina API, returns rich metadata (title, description, publish time).</li> <li>crawl4ai_fetch_webpage_content \u2014 Most feature-rich; runs a local headless browser, supports BM25 filtering and pruning to extract relevant content.</li> <li>webthinker_fetch_webpage_content_async \u2014 Lightweight async parser; supports PDFs and snippet-based context extraction.</li> </ul>"}]}